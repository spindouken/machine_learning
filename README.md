# Machine Learning Project Repository

Welcome to my **Machine Learning Project Repository**!<br>
This repository contains a variety of projects organized under different topics in machine learning and mathematics. Each main directory (`math`, `supervised_learning`, `unsupervised_learning`) groups related projects and concepts for easy access.

## Contents
- [Math](#math)
- [Supervised Learning](#supervised_learning)
- [Unsupervised Learning](#unsupervised_learning)

## Directory Structure

### [math](math/)
- **[linear_algebra](math/linear_algebra)**  
  Contains projects related to linear algebra concepts implemented with NumPy, covering fundamental operations, matrix transformations, and applications in machine learning.

- **[plotting](math/plotting)**  
  Demonstrates data visualization techniques using Matplotlib, showcasing different types of plots and charts to understand and interpret data.

- **[calculus](math/calculus)**  
  Explores calculus concepts through Python, covering both differentiation and integration techniques with applications in machine learning.

- **[probability](math/probability)**  
  Implements probability distributions from scratch, including Poisson, exponential, normal, and binomial distributions, providing a foundation for probabilistic modeling.

- **[advanced_linear_algebra](math/advanced_linear_algebra)**  
  Focuses on advanced linear algebra topics such as eigenvalues, eigenvectors, and singular value decomposition, with applications in dimensionality reduction.

- **[multivariate_prob](math/multivariate_prob)**  
  Contains projects related to multivariate probability concepts, with practical examples in probabilistic reasoning and statistical modeling.

- **[bayesian_prob](math/bayesian_prob)**  
  Covers Bayesian probability, including concepts such as Bayes' theorem and posterior distribution, essential for Bayesian inference.

- **[convolutions_and_pooling](math/convolutions_and_pooling)**  
  Introduces convolution and pooling operations, foundational techniques in convolutional neural networks (CNNs).

### [supervised_learning](supervised_learning/)
- **[classification](supervised_learning/classification)**  
  Includes a binary image classifier built from scratch using NumPy, demonstrating the basics of supervised classification.

- **[tensorflow](supervised_learning/tensorflow)**  
  Basic projects using TensorFlow, covering its setup, basic operations, and applications in model building and training.

- **[optimization](supervised_learning/optimization)**  
  Explores optimization algorithms, including gradient descent and its variants, essential for efficient model training.

- **[error_analysis](supervised_learning/error_analysis)**  
  Discusses error analysis techniques for evaluating model performance, identifying common sources of error, and improving model accuracy.

- **[regularization](supervised_learning/regularization)**  
  Examines regularization techniques such as L1 and L2 regularization to prevent overfitting in machine learning models.

- **[keras](supervised_learning/keras)**  
  Contains projects using Keras (built on TensorFlow 2), focusing on model creation, training, and evaluation with a high-level API.

- **[cnn](supervised_learning/cnn)**  
  Provides introductory projects on convolutional neural networks (CNNs), demonstrating basic image classification tasks.

- **[deep_cnns](supervised_learning/deep_cnns)**  
  Explores deep convolutional architectures, showcasing how to stack multiple convolutional layers for more complex feature extraction.

- **[transfer_learning](supervised_learning/transfer_learning)**  
  Demonstrates transfer learning techniques, reusing pretrained models to improve training efficiency on new tasks.

- **[object_detection](supervised_learning/object_detection)**  
  Projects focused on object detection, identifying and locating objects within images using CNN-based methods.

- **[RNNs](supervised_learning/RNNs)**  
  Introduces recurrent neural networks (RNNs), covering GRU, LSTM, and bidirectional RNNs for sequential data analysis.

- **[time_series](supervised_learning/time_series)**  
  Includes a time series forecasting project, using RNNs to predict future values in financial data, such as BTC prices.

- **[word_embeddings](supervised_learning/word_embeddings)**  
  Covers word embedding techniques (e.g., bag of words, TF-IDF, word2vec, fastText, ELMo) for natural language processing.

- **[nlp_metrics](supervised_learning/nlp_metrics)**  
  Provides NLP evaluation metrics projects, including N-GRAM, BLEU, and ROUGE scores, to evaluate text generation and translation models.

- **[transformer_apps](supervised_learning/transformer_apps)**  
  Demonstrates applications of transformer models in tasks such as text classification, summarization, and machine translation.

- **[qa_bot](supervised_learning/qa_bot)**  
  Contains a question-answering bot built using BERT, performing semantic search and question-answering tasks.

### [unsupervised_learning](unsupervised_learning/)
- **[clustering](unsupervised_learning/clustering)**  
  Covers clustering techniques such as K-means and hierarchical clustering for grouping similar data points in an unsupervised manner.

- **[dimensionality_reduction](unsupervised_learning/dimensionality_reduction)**  
  Projects on dimensionality reduction methods, such as PCA and t-SNE, to reduce feature space for better visualization and performance.

- **[hmm](unsupervised_learning/hmm)**  
  Introduces Hidden Markov Models (HMMs) for sequential data analysis, covering both training and prediction.

- **[hyperparameter_tuning](unsupervised_learning/hyperparameter_tuning)**  
  Explores techniques for hyperparameter tuning to optimize model performance, including grid search and random search.

- **[autoencoders](unsupervised_learning/autoencoders)**  
  Contains projects on autoencoders, including sparse, convolutional, and variational types, for applications in data compression and feature learning.

- **[GANs](unsupervised_learning/GANs)**  
  Focuses on Generative Adversarial Networks (GANs), covering both basic GANs and deep convolutional GANs (DCGANs) for generating synthetic data.
